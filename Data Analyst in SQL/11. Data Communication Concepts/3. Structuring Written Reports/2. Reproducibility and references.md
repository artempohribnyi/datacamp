# 1. Reproducibility and references

Good job working on those reports! Understanding how to structure a report is tremendously important.

# 2. Written report

A fundamental part of communicating our findings, it making sure a report is clear and reproducible.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/80424bb2-0b98-4962-aee3-53591c78bce8)

# 3. Reproducibility example

For example, say we have a friend that always cooks this amazing chocolate cake. We got at his place and follow his exact steps using his equipment: that's reproducibility. We trust he can actually bake this delicious cake. On a data project, if you run your Jupyter notebook again today and tomorrow, our results should be identical (provided the dataset hasn't changed).

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/46d56f7e-2684-4514-b50c-071395b7b6b9)

# 4. Replicability example

In baking replicability would be the ability to cook that cake again ourselves, following the recipe but using our own utensils and ingredients. In a data project, it would be the ability to obtain similar results using the same general approach, but a different environment (the data is processed in the same way, but using a different language on a different OS).

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/f9152b14-c0a2-4929-babe-dedbfbbf635b)

# 5. Reproducibility and replicability virtues

This scientific approach is crucial because it prevents duplication of effort and allows other data scientist to build upon preexisting work, enabling them to build upon previous work and focus on new challenges. Last but not least, it allows peer-reviewing. Although we tend to focus on coding examples in this course, you should always make sure that your code is easily reproducible and replicable, whether we use Excel spreadsheets, Tableau visualizations or Jupyter Notebooks. What matters is to keep track of how the results were produced.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/f5f2e3ec-29e0-4196-963c-0df390ec62b3)

# 6. Best practices

We should document all the scripts we used to obtain our results using, for example, comments in our code, and list all the packages used in our environment. One helpful technique is to use a version control system (like Git), that tracks all the changes and versions of our scripts.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/fee052d5-c0fd-4980-b493-28c8f6213dc9)

# 7. Best practices

We should avoid doing any manual manipulation of the data. We must never change the dataset directly in an editor. If possible, we should save all versions of our dataset. Also, we should save the raw data together with a script with intermediate steps. It can help us tell the story of our data transformation and create a narrative around it. Such a clear view ensures we know at any point what is happening with the data, and therefore can adapt and resolve problems. Take a data imputation example. There was a bug in the data pipeline, and you're told you can use the average values to impute missing values for a specific product. You go ahead and push the edits manually, then close your editor. Right after, your colleague informs you that actually, those products weren't available for sale on those dates, so the missing values should be zero. The data is already overwritten, so it's going to be hard to know which values were changed in the first place. Had we versioned the changes, it would be much simpler.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/c62b7c6e-8340-4500-a7ac-2fce88e82a24)

# 8. Best practices

We usually use machine learning algorithms or pipelines to create our workflow. Some of them might involve randomness techniques. We can usually set a random seed and introduce reproducibility into our model outputs. The random seed controls confounding variables: it lets us ensure a change was due to the model and not just randomness.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/c532ebb8-3642-4db2-90da-4aff45209e09)

# 9. Best practices

Interpretability is the degree to which a human can understand the cause of a decision or can consistently predict a model's result. Telling a story with a compelling narrative helps our stakeholders understand and interpret our findings. Because they are able to understand them, our conclusions can be reproduced.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/d2486fe8-9b0f-45e4-87c3-b630f511329d)

1 Molnar C. Interpretable Machine Learning. 2019.

# 10. Best practices

Lastly, we should always correctly cite other people's work used in our analysis.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/60215e64-1784-40c9-a85c-9b00bf33f50e)

# 11. References

Citations are the basic information required to identify and locate a specific publication

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/f32b1e16-421b-4b03-8d67-2728a4c610fa)

# 12. References

There are different styles, but they all have the same underlying logic, with slight variations. The most common style is APA, which uses in-text citations, putting the author name first and the date of publication next.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/59d2d860-1560-4348-92d6-866cc9857600)

# 13. Reference

There are a number of reference management tools that can ease the burden of tracking all the citations. They help us automatically switch styles, and search online sources for references. EndNote, Mendeley, and RefWorks are some examples, but there are many more.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/1f5b8e87-588e-43cc-8796-967431a7c770)

# 14. References

In a business context, these editions rules are much more relaxed. Most people will simply include a hyperlink to the source. What matters in the end is that the information is easy to retrieve, if the reader wants to refer to the sources material.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/ecc62122-1683-4202-aec3-9b43dd8c6b09)

# 15. Let's practice!

Let's see how you can make your work more reproducible!

# Replicate me

Your manager asks you to write a report on your customer churn project for your peers at the New York office. She mentions that the team wants to replicate your work. After wrapping up the report, you add a link to your code repository. She looks confused and asks you why you did that.

You explain: If the New York team wants to replicate my work, then they should have access to the same ___ and the same ___ I used. However, if they want to achieve ___ , they can use their own set of tools.

Fill in the blank spaces by choosing the correct word combination from the options.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/52260cbf-5ebd-4fc2-8e68-f3ad1023af41)

Reproducibility refers to the ability to obtain similar results that another team but using different data and code. Nowadays, there is a reproducibility crisis, so it's very important that as a data science you follow best practices.

# Same results

Your manager is very interested in learning more about reproducibility. She asks you to give a short presentation at the weekly meeting. You're going to introduce the best practices to create reproducible data science results.

You prepare a slide presenting bad practices, and another one highlighting best practices.

Which of the following statements are considered best practices in reproducibility, and which should be avoided?

Correctly classify the statements as best or bad practices.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/7626b50a-9c5a-4821-85b4-d87a3fdbadc8)

Ensuring reproducibility might make people confident with your work and use it to drive data-decision making. The way you write a report can contribute to this process.

