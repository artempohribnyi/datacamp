# 1. Creating Temporary Tables

Up to this point, you've run queries and viewed the results. But what if you want to keep the results of a query around for reference? You need special permissions in a database to create or update tables, but most users can create temporary tables that only they can see and that only last for the duration of a database session.

# 2. Syntax

One way to create a temporary table is with a select query. The results of the query are saved as a table that you can use later. To do this, we preface any select query with the words create temp table, then a name for the table we're creating, and finally the keyword as. This copies the result of the select query into a new table that has no connection to the original table. There are other ways to create temporary tables as well. You may have seen the "select into" syntax before. You add a special clause into the middle of a select query to direct the results into a new temp table. In this example, the added clause is the middle line of code. Both of these queries do the same thing, just with different syntax. We're going to use the create table syntax in this course. It's the method recommended by Postgres, and it allows you to use options not available with the "select into" syntax.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/b4f56174-e15f-4dae-8da2-0c00a7d86aa9)

# 3. Create a table

As an example let's make a temporary table called top_companies with just the rank and title of the top 10 companies in fortune500. We preface our select query with the create temp table syntax. After we've created the table, we can then select from it. Note that the column names are taken from the column names of the result

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/c1ab7ccb-947e-4284-9033-ed671d6f0fb8)

# 4. Insert into table

We can also insert new rows into a table after we've created it. We use an "insert into" statement with the name of the table, followed by a select query that will generate the rows we want to add to the table. The columns generated by the select query must match those already in the table. Here we add companies with ranks 11 to 20 to the table. In many database clients, after you run the command,you'll get a confirmation message that 10 rows were inserted into the table. In the DataCamp editor, you won't see any message when rows are inserted. Now if we select from the temp table top_companies again, you can see the new rows have been added.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/6518d96e-5acc-406d-98e1-b5d8877a8ca2)

# 5. Delete (drop) table

To delete a table, use the drop table command. The table will be deleted immediately without warning. Dropping a table can be useful if you made a mistake when creating it or when inserting values into it. Temporary tables will also be deleted automatically when you disconnect from the database. A variation on the drop table command adds the clause if exists before the table name. This means to only try to delete the table after confirming that such a table exists. This variation is often used in scripts because it won't cause an error if the table doesn't exist.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/2de00ffd-9fa9-4bde-aabc-8b2253aefd36)

# 6. Time to create some tables!

Temporary tables can be useful for keeping results for later reference, or for breaking complicated queries into smaller pieces. Now it's your turn to create some tables of your own.

# Create a temp table

Find the Fortune 500 companies that have profits in the top 20% for their sector (compared to other Fortune 500 companies).

To do this, first, find the 80th percentile of profit for each sector with

percentile_disc(fraction) 
WITHIN GROUP (ORDER BY sort_expression)
and save the results in a temporary table.

Then join fortune500 to the temporary table to select companies with profits greater than the 80th percentile cut-off.

Create a temporary table called profit80 containing the sector and 80th percentile of profits for each sector.
Alias the percentile column as pct80.

```
-- To clear table if it already exists;
-- fill in name of temp table
DROP TABLE IF EXISTS profit80;

-- Create the temporary table
CREATE TEMP TABLE profit80 AS 
  -- Select the two columns you need; alias as needed
  SELECT sector, 
         PERCENTILE_DISC(0.8) WITHIN GROUP (ORDER BY profits) AS pct80
    -- What table are you getting the data from?
    FROM fortune500
   -- What do you need to group by?
   GROUP BY sector;
   
-- See what you created: select all columns and rows 
-- from the table you created
SELECT * 
  FROM profit80;
```
![image](https://github.com/artempohribnyi/datacamp/assets/113499718/3f6564cc-8477-42e9-af11-f2419861748a)

* Using the profit80 table you created in step 1, select companies that have profits greater than pct80.
* Select the title, sector, profits from fortune500, as well as the ratio of the company's profits to the 80th percentile profit.

```
-- Code from previous step
DROP TABLE IF EXISTS profit80;

CREATE TEMP TABLE profit80 AS
  SELECT sector, 
         percentile_disc(0.8) WITHIN GROUP (ORDER BY profits) AS pct80
    FROM fortune500 
   GROUP BY sector;

-- Select columns, aliasing as needed
SELECT title, fortune500.sector, 
       profits, profits/pct80 AS ratio
-- What tables do you need to join?  
  FROM fortune500 
       LEFT JOIN profit80
-- How are the tables joined?
       ON fortune500.sector = profit80.sector
-- What rows do you want to select?
 WHERE profits > pct80;
```

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/db1da53c-c627-41f3-a29d-59290bacd712)

Instead of creating a temporary table, you could do this in one step with a subquery. But if you'll use the same subquery multiple times, a temporary table can be a good option.

# Create a temp table to simplify a query

The Stack Overflow data contains daily question counts through 2018-09-25 for all tags, but each tag has a different starting date in the data.

Find out how many questions had each tag on the first date for which data for the tag is available, as well as how many questions had the tag on the last day. Also, compute the difference between these two values.

To do this, first compute the minimum date for each tag.

Then use the minimum dates to select the question_count on both the first and last day. To do this, join the temp table startdates to two different copies of the stackoverflow table: one for each column - first day and last day - aliased with different names.

1. First, create a temporary table called startdates with each tag and the min() date for the tag in stackoverflow.

```
-- To clear table if it already exists
DROP TABLE IF EXISTS startdates;

-- Create temp table syntax
CREATE TEMP TABLE startdates AS
-- Compute the minimum date for each what?
SELECT tag,
       MIN(date) AS mindate
  FROM stackoverflow
 -- What do you need to compute the min date for each tag?
 GROUP BY tag;
 
 -- Look at the table you created
 SELECT * 
   FROM startdates;
```
![image](https://github.com/artempohribnyi/datacamp/assets/113499718/b2b36200-6dd2-4e92-a21d-6b335b17f704)

* Join startdates to stackoverflow twice using different table aliases.
* For each tag, select mindate, question_count on the mindate, and question_count on 2018-09-25 (the max date).
* Compute the change in question_count over time.

```
-- To clear table if it already exists
DROP TABLE IF EXISTS startdates;

CREATE TEMP TABLE startdates AS
SELECT tag, min(date) AS mindate
  FROM stackoverflow
 GROUP BY tag;
 
-- Select tag (Remember the table name!) and mindate
SELECT startdates.tag, 
       mindate, 
       -- Select question count on the min and max days
	   so_min.question_count AS min_date_question_count,
       so_max.question_count AS max_date_question_count,
       -- Compute the change in question_count (max- min)
       so_max.question_count - so_min.question_count AS change
  FROM startdates
       -- Join startdates to stackoverflow with alias so_min
       INNER JOIN stackoverflow AS so_min
          -- What needs to match between tables?
          ON startdates.tag = so_min.tag
         AND startdates.mindate = so_min.date
       -- Join to stackoverflow again with alias so_max
       INNER JOIN stackoverflow AS so_max
       	  -- Again, what needs to match between tables?
          ON startdates.tag = so_max.tag
         AND so_max.date = '2018-09-25';
```

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/d38d3e9c-d7e4-4b99-aee6-75c6d29f32a1)

The main query here was already complicated, so creating the temporary table first helped simplify the analysis.

# Insert into a temp table

While you can join the results of multiple similar queries together with UNION, sometimes it's easier to break a query down into steps. You can do this by creating a temporary table and inserting rows into it.

Compute the correlations between each pair of profits, profits_change, and revenues_change from the Fortune 500 data.

The resulting temporary table should have the following structure:
![image](https://github.com/artempohribnyi/datacamp/assets/113499718/5a999daf-42c5-4c90-8f8c-7805c26d5a32)
Recall the round() function to make the results more readable:

round(column_name::numeric, decimal_places)
Note that Steps 1 and 2 do not produce output. It is normal for the query result pane to say "Your query did not generate any results."

1. Create a temp table correlations.

* Compute the correlation between profits and each of the three variables (i.e. correlate profits with profits, profits with profits_change, etc).
* Alias columns by the name of the variable for which the correlation with profits is being computed.
  
```
DROP TABLE IF EXISTS correlations;

-- Create temp table 
CREATE TEMP TABLE correlations AS
-- Select each correlation
SELECT 'profits'::varchar AS measure,
       -- Compute correlations
       CORR(profits, profits) AS profits,
       CORR(profits, profits_change) AS profits_change,
       CORR(profits, revenues_change) AS revenues_change
  FROM fortune500;
```

2. Insert rows into the correlations table for profits_change and revenues_change.

```
DROP TABLE IF EXISTS correlations;

CREATE TEMP TABLE correlations AS
SELECT 'profits'::varchar AS measure,
       corr(profits, profits) AS profits,
       corr(profits, profits_change) AS profits_change,
       corr(profits, revenues_change) AS revenues_change
  FROM fortune500;

-- Add a row for profits_change
-- Insert into what table?
INSERT INTO correlations
-- Follow the pattern of the select statement above
-- Using profits_change instead of profits
SELECT 'profits_change'::varchar AS measure,
       corr(profits_change, profits) AS profits,
       corr(profits_change, profits_change) AS profits_change,
       corr(profits_change, revenues_change) AS revenues_change
  FROM fortune500;

-- Repeat the above, but for revenues_change
INSERT INTO correlations
SELECT 'revenues_change'::varchar AS measure,
       corr(revenues_change, profits) AS profits,
       corr(revenues_change, profits_change) AS profits_change,
       corr(revenues_change, revenues_change) AS revenues_change
  FROM fortune500;
```

3. Select all rows and columns from the correlations table to view the correlation matrix.

* First, you will need to round each correlation to 2 decimal places.
* The output of corr() is of type double precision, so you will need to also cast columns to numeric.

```
DROP TABLE IF EXISTS correlations;

CREATE TEMP TABLE correlations AS
SELECT 'profits'::varchar AS measure,
       corr(profits, profits) AS profits,
       corr(profits, profits_change) AS profits_change,
       corr(profits, revenues_change) AS revenues_change
  FROM fortune500;

INSERT INTO correlations
SELECT 'profits_change'::varchar AS measure,
       corr(profits_change, profits) AS profits,
       corr(profits_change, profits_change) AS profits_change,
       corr(profits_change, revenues_change) AS revenues_change
  FROM fortune500;

INSERT INTO correlations
SELECT 'revenues_change'::varchar AS measure,
       corr(revenues_change, profits) AS profits,
       corr(revenues_change, profits_change) AS profits_change,
       corr(revenues_change, revenues_change) AS revenues_change
  FROM fortune500;

-- Select each column, rounding the correlations
SELECT measure, 
       ROUND(profits::numeric, 2) AS profits,
       ROUND(profits_change::numeric, 2) AS profits_change,
       ROUND(revenues_change::numeric, 2) AS revenues_change
  FROM correlations;
```

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/2a8ddefa-65c3-42f8-a680-fd99a5ab2f81)

When specifying the number of decimal places with the round or trunc functions, the first value must be of type numeric. The correlations were double precision before being cast to numeric.


