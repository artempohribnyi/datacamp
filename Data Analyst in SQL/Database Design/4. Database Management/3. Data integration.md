# 1. Data integration

You're now familiar with tables, databases, schemas and permissions. But what if your data is spread across different databases, formats, schemas and technologies? That's where data integration comes into play.

# 2. What is data integration

Data Integration combines data from different sources, formats, technologies to provide users with a translated and unified view of that data. Let's look at some examples.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/1397231f-2492-4def-9f33-418abf95a5b4)

# 3. Business case examples

A company could want a 360-degree customer view, to see all information departments have about a customer in a unified place. Another example is one company acquiring another, and needs to combine their respective databases. Legacy systems are also a common case of data integration. An insurance company with claims in old and new systems, would need to integrate data to query all claims at once.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/b875f8fc-0997-4ec2-b8e0-9856088c418e)

# 4. Unified data model

There are a few things to consider when integrating data. What is your final goal? Your unified data model could be used to create dashboards, like graphs of daily sales, or data products, such as a recommendation engine. The final data model needs to be fast enough for your use-case.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/152d8e15-0ad3-421e-a3c6-a7a0f4994448)

# 5. Data sources

The necessary information is held in these data sources.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/03a3f843-f2df-47f1-9101-da7efa8be6b6)

# 6. Data sources format

Which formats is each data source stored in? For example, it could be PostgreSQL, MongoDB or a CSV. You'll learn more about database management systems in the next lesson.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/93342143-4f7b-44fb-ac94-de7efb1ce0c6)

# 7. Unified data model format

Which format should the unified data model take? For example, Redshift, a data warehouse service offered by AWS.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/c7baba62-7866-4ca2-b393-16fc8e318d69)

# 8. Example: DataCamp

Say DataCamp is launching a skill assessment module. Marketing wants to know which customers to target. They need information from sales, stored in PostgreSQL, to see which customers can afford the new product. They also need information from the product department, stored in MongoDB to identify potential early adopters.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/fb472cb6-1192-49b9-aad7-fa7c8cc22d10)

# 9. Update cadence - sales

Next, how often do you want to update the data? Updating daily would probably be sufficient for sales data.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/fe57a0a9-9cba-44b5-995c-d4af258fdb7d)

# 10. Update cadence - air traffic

For a scenario like air traffic, you want real time updates.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/2e5fb6ab-85ee-4430-8775-2edc11595208)

# 11. Different update cadences

Your data sources can have different update cadences.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/11fe0079-d076-46f7-b44d-b22c3c32a401)

# 12. So simple?

So thatâ€™s it? You just plug your sources to the unified data model?

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/1b445909-b9ef-472f-8fc3-63b77355a57f)

# 13. Not really

Not really. Your sources are in different formats, you need to make sure they can be assembled together.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/50e94c61-f8ff-4586-beaf-bf5d7417a5cc)

# 14. Transformations

Enter transformations. A transformation is a program that extracts content from the table and transforms it into the chosen format for the unified model. These transformations can be hand-coded, but you would have to make and maintain a transformation for each data source.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/b4fb7aa3-35dc-4284-a432-78339664b67f)

# 15. Transformation - tools

You can also use a data integration tool, which provides the needed ETL. For example Apache Airflow or Scriptella.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/39d9abee-1e2d-41f2-af82-7d52f18dcde0)

# 16. Choosing a data integration tool

When choosing your tool, you must ensure that it's flexible enough to connect to all of your data sources. Reliable, so that it can still be maintained in a year. And it should scale well, anticipating an increase in data volume and sources.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/f1906bfa-0411-497f-b47d-2718571df2c3)

# 17. Automated testing and proactive alerts

You should have automated testing and proactive alerts. If any data gets corrupted on its way to the unified data model, the system lets you know. For example, you could aggregate sales data after each transformation and ensure that the total amount remains the same.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/0c7c0bd8-9436-4d73-9bad-4e1bced60171)

# 18. Security

Security is also a concern: if data access was originally restricted, it should remain restricted in the unified data model.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/70539515-ba6b-4932-9d44-660a7d26b4c9)

# 19. Security - credit card anonymization

For example, business analysts using the unified data model should not have access to the credit card numbers. You should anonymize the data during ETL so that analysts can only access the first four numbers, to identify the type of card being used.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/cb36bf06-7411-4b45-b879-a8c480d366b3)

# 20. Data governance - lineage

For data governance purposes, you need to consider lineage: for effective auditing, you should know where the data originated and where it is used at all times.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/7fede3cf-a65d-4c17-9ef8-2052681d63a2)

# 21. Let's practice!

Now it's your turn to practice the ins and outs of data integration.

# Data integration do's and dont's

You just learned a lot about data integration, let's check your understanding of the concepts.

Categorize the following items as being True or False when talking about data integration.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/bf3831b0-b89f-4751-9434-ba3505944b92)

Looks like you have a good grasp on what you should take into account when looking at and can expect from a good data integration solution.

# Analyzing a data integration plan

You're a data analyst in a hospital that wants to make sure there is enough cough medicine should an epidemic break out. For this, you need to combine the historical health records with the upcoming appointments to see if you can detect a pattern similar to the last cold epidemic. Then, you need to make sure there is sufficient stock available or if the stock should be increased. To help tackle this problem, you created a data integration plan.

Which risk is not clearly indicated on the data integration plan?

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/b3720909-458b-4378-9bf7-8f7c675e7fa3)

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/9e2f28b4-426a-4a2d-a735-9c66aea19648)

When working with sensitive data it is important to think about permissions. By default you should have the same access rights before and after data integration. If part of the data is essential, it should be anonymized, in this case you can keep the illnesses but remove identifying information.


