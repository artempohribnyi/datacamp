# 1. Storing data

Let's discuss the different ways you can store data.

# 2. Structuring data

Data can be stored in three different levels. The first is structured data, which is usually defined by schemas. Data types and tables are not only defined, but relationships between tables are also defined, using concepts like foreign keys. The second is unstructured data, which is schemaless and data in its rawest form, meaning it's not clean. Most data in the world is unstructured. Examples include media files and raw text. The third is semi-structured data, which does not follow a larger schema, rather it has an ad-hoc self-describing structure. Therefore, it has some structure. This is an inherently vague definition as there can be a lot of variation between structured and unstructured data. Examples include NoSQL, XML, and JSON, which is shown here on the right.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/d96e2f37-d22d-4981-860d-f839e3a15eff)

# 3. Structuring data

Because its clean and organized, structured data is easier to analyze. However, it's not as flexible because it needs to follow a schema, which makes it less scalable. These are trade-offs to consider as you move between structured and unstructured data.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/4b43c4cd-d4f4-4d04-a382-5bb12e79c88f)

1 Flower by Sam Oth and Database Diagram by Nick Jenkins via Wikimedia Commons https://commons.wikimedia.org/wiki/File:Languages_xml.png

# 4. Storing data beyond traditional databases

You should already be familiar with traditional databases. They generally follow relational schemas. Operational databases, which are used for OLTP, are an example of traditional databases. Decades ago, traditional databases used to be enough for data storage. Then as data analytics took off, data warehouses were popularized for OLAP approaches. And, now in the age of big data, we need to analyze and store even more data, which is where the data lake comes in. I use the term "traditional databases" because many people consider data warehouses and lakes to be a type of database.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/c39bbe0e-6324-46d0-8892-df88cf579e88)

# 5. Data warehouses

Data warehouses are optimized for read-only analytics. They combine data from multiple sources and use massively parallel processing for faster queries. In their database design, they typically use dimensional modeling and a denormalized schema. We will walk through both of these terms later in the course. Amazon, Google, and Microsoft all offer data warehouse solutions, known as Redshift, Big Query, and Azure SQL Data Warehouse, respectively. A data mart is a subset of a data warehouse dedicated to a specific topic. Data marts allow departments to have easier access to the data that matters to them.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/b9291e30-db62-4ed3-b2ef-6b3e04eaf322)

# 6. Data lakes

Technically, traditional databases and warehouses can store unstructured data, but not cost-effectively. Data Lake storage is cheaper because it uses object storage as opposed to the traditional block or file storage. This allows massive amounts of data to be stored effectively of all types, from streaming data to operational databases. Lakes are massive because they store all the data that might be used. Data lakes are often petabytes in size - that's 1,000 terabytes! Unstructured data is the most scalable, which permits this size. Lakes are schema-on-read, meaning the schema is created as data is read. Warehouses and traditional databases are classified as schema-on-write because the schema is predefined. Data lakes have to be organized and cataloged well; otherwise, it becomes an aptly named "data swamp." Data lakes aren't only limited to storage. It's becoming popular to run analytics on data lakes. This is especially true for tasks like deep learning and data discovery, which needs a lot of data that doesn't need to be that "clean." Again, the big three cloud providers all offer a data lake solution.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/f693aaa0-76b1-40de-8125-40256607fcf3)

# 7. Extract, Transform, Load or Extract, Load, Transform

When we think about where to store data, we have to think about how data will get there and in what form. Extract Transform Load and Extract Load Transform are two different approaches for describing data flows. They get into the intricacies of building data pipelines, which we will not get into. ETL is the more traditional approach for warehousing and smaller-scale analytics. But, ELT has become common with big data projects. In ETL, data is transformed before loading into storage - usually to follow the storage's schema, as is the case with warehouses. In ELT, the data is stored in its native form in a storage solution like a data lake. Portions of data are transformed for different purposes, from building a data warehouse to doing deep learning.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/aa1fd589-3818-4110-ae1b-3e718a626d4c)

# 8. Let's practice!

Let's practice!

Name that data type!
In the previous video, you learned about structured, semi-structured, and unstructured data. Structured data is the easiest to analyze because it is organized and cleaned. On the other hand, unstructured data is schemaless, but scales well. In the middle we have semi-structured data for everything in between.

Each of these cards hold a type of data. Place them in the correct category.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/d6bb61d6-4603-4fc6-b8cc-77ab11f99940)

From these real-life examples, can you see why unstructured data is easier to scale than structured data?

# Ordering ETL Tasks

You have been hired to manage data at a small online clothing store. Their system is quite outdated because their only data repository is a traditional database to record transactions.

You decide to upgrade their system to a data warehouse after hearing that different departments would like to run their own business analytics. You reason that an ELT approach is unnecessary because there is relatively little data (< 50 GB).

In the ETL flow you design, different steps will take place. Place the steps in the most appropriate order.

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/f0fef300-adde-4de1-b9e3-69d2db918fc6)

In ETL, raw data is cleaned before being stored. This makes it accessible and ready to use.

# Recommend a storage solution

When should you choose a data warehouse over a data lake?

![image](https://github.com/artempohribnyi/datacamp/assets/113499718/ee8df3c3-9ed9-465f-a4d2-3dff0a44b6c7)

Analysts will appreciate working in a data warehouse more because of its organization of structured data that make analysis easier.
